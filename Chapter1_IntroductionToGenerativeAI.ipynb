{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee4d53e",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to Generative AI (Gen AI)\n",
    "\n",
    "## What is Generative AI?\n",
    "Generative AI refers to a class of artificial intelligence that is capable of creating new data that mimics the characteristics of existing data. Unlike traditional AI models that primarily classify or predict based on input data, generative AI models focus on generating original outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### Definition of Generative AI\n",
    "Generative AI uses patterns learned from data to generate new and creative outputs. These outputs can take many forms, including:\n",
    "- **Text**: Generating coherent and contextually relevant sentences.\n",
    "- **Images**: Creating photorealistic images or artistic designs.\n",
    "- **Audio**: Synthesizing speech or music.\n",
    "- **Video**: Producing animations or video sequences.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples of Applications\n",
    "1. **Text Generation**: ChatGPT, automated content creation, summarization.\n",
    "2. **Image Synthesis**: Stable Diffusion, DALLÂ·E, AI art tools.\n",
    "3. **Music Composition**: AI tools that generate melodies, harmonies, or even full songs.\n",
    "4. **Code Assistance**: Writing and debugging code (e.g., GitHub Copilot, StarCoder).\n",
    "\n",
    "Below is an illustration of how generative AI models are applied:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2f58b",
   "metadata": {},
   "source": [
    "![Applications of Generative AI](https://upload.wikimedia.org/wikipedia/commons/2/26/AI_workflow_example.svg)\n",
    "\n",
    "This diagram highlights key applications of generative AI across domains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd752ba",
   "metadata": {},
   "source": [
    "### How Generative AI Differs from Traditional AI Models\n",
    "\n",
    "| **Aspect**           | **Traditional AI**                          | **Generative AI**                        |\n",
    "|-----------------------|---------------------------------------------|------------------------------------------|\n",
    "| **Focus**            | Predicting or classifying input data.       | Generating new data based on patterns.   |\n",
    "| **Output**           | Labels, categories, numerical predictions.  | New text, images, audio, or other data. |\n",
    "| **Examples**         | Spam filters, sentiment analysis.           | ChatGPT, Stable Diffusion.              |\n",
    "| **Techniques Used**  | Supervised learning, decision trees.         | Transformers, GANs, VAEs.               |\n",
    "\n",
    "Generative AI leverages **unsupervised** or **semi-supervised learning** to create innovative outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c68ddf",
   "metadata": {},
   "source": [
    "### Role of Large Language Models (LLMs) in Generative AI\n",
    "\n",
    "Large Language Models (LLMs) like GPT, BLOOM, and LLaMA are central to text-based generative AI. These models:\n",
    "- Use **Transformer architecture** for efficient processing of sequential data.\n",
    "- Are trained on massive datasets, making them highly versatile for various tasks.\n",
    "- Serve as the backbone for applications like:\n",
    "  - Conversational agents (e.g., ChatGPT).\n",
    "  - Content summarization.\n",
    "  - Creative writing.\n",
    "\n",
    "#### Core Concepts of LLMs:\n",
    "1. **Pretraining and Fine-Tuning**: Models are pretrained on a large corpus and fine-tuned for specific tasks.\n",
    "2. **Self-Attention Mechanism**: Allows the model to focus on relevant parts of the input sequence.\n",
    "3. **Scalability**: LLMs scale well with increased data and parameters, resulting in improved performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Architecture: Transformer\n",
    "Below is a simplified diagram of the Transformer architecture powering LLMs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cc00f",
   "metadata": {},
   "source": [
    "![Transformer Architecture](https://upload.wikimedia.org/wikipedia/commons/1/10/Transformer.svg)\n",
    "\n",
    "Transformers enable generative AI models to handle long-range dependencies effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1788d7d",
   "metadata": {},
   "source": [
    "## Code Example: Generating Synthetic Data with NumPy\n",
    "\n",
    "Let's generate some synthetic data using NumPy to simulate the process of generative models learning patterns in data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data using Gaussian distribution\n",
    "def generate_synthetic_data(samples, mean, std_dev):\n",
    "    return np.random.normal(mean, std_dev, samples)\n",
    "\n",
    "# Parameters\n",
    "samples = 1000\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Generate data\n",
    "data = generate_synthetic_data(samples, mean, std_dev)\n",
    "\n",
    "# Plot the data\n",
    "plt.hist(data, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Synthetic Data Generated with Gaussian Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63538788",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. What is the primary focus of Generative AI?\n",
    "   - A. Classifying input data.\n",
    "   - B. Generating new data based on learned patterns.\n",
    "   - C. Reducing dimensionality of data.\n",
    "\n",
    "2. Which of the following is an example of a generative AI application?\n",
    "   - A. Spam detection.\n",
    "   - B. Automated content creation.\n",
    "   - C. Predicting stock prices.\n",
    "\n",
    "---\n",
    "\n",
    "### Answers:\n",
    "1. B. Generating new data based on learned patterns.\n",
    "2. B. Automated content creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370e37a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Task:\n",
    "Write a Python function to generate synthetic data using a uniform distribution and visualize it as a histogram.\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "- Number of samples: 500\n",
    "- Range: [0, 10]\n",
    "\n",
    "Output:\n",
    "- A histogram of the generated data.\n",
    "\n",
    "---\n",
    "\n",
    "### Solution:\n",
    "Below is a sample implementation for the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa55590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data using a uniform distribution\n",
    "def generate_uniform_data(samples, lower_bound, upper_bound):\n",
    "    return np.random.uniform(lower_bound, upper_bound, samples)\n",
    "\n",
    "# Parameters\n",
    "samples = 500\n",
    "lower_bound = 0\n",
    "upper_bound = 10\n",
    "\n",
    "# Generate data\n",
    "uniform_data = generate_uniform_data(samples, lower_bound, upper_bound)\n",
    "\n",
    "# Plot the data\n",
    "plt.hist(uniform_data, bins=20, alpha=0.7, color='green')\n",
    "plt.title('Synthetic Data Generated with Uniform Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
